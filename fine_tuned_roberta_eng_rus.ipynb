{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine-tuned_roberta_eng_rus",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4qO-Fjj2tPS"
      },
      "source": [
        "corpus = 'previews' #'recommended'\n",
        "path_raw_fiction_previews = '/content/gdrive/MyDrive/fiction_previews/raw_fiction_previews/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rexJ0PvFRB3r"
      },
      "source": [
        "#Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nooIAeM4LLuR"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqk25yvmxvzY"
      },
      "source": [
        "import pandas as pd\n",
        "import os, zipfile, pickle\n",
        "import numpy as np\n",
        "\n",
        "if corpus == 'recommended':\n",
        "  \n",
        "  with zipfile.ZipFile(\"/content/gdrive/MyDrive/NSU Workshop'21 - Readability/Корпусы/fiction_recommended/fragments.zip\", 'r') as zip_ref:\n",
        "      zip_ref.extractall(\"/content/1\")\n",
        "\n",
        "  ###################### train\n",
        "  files = os.listdir(\"/content/1/fragments/train\")\n",
        "  path = \"/content/gdrive/MyDrive/NSU Workshop'21 - Readability/Корпусы/fiction_recommended/ratings_train.csv\"\n",
        "  df = pd.read_csv(path, header = None)\n",
        "\n",
        "  train_labels = []\n",
        "  for f in files:\n",
        "    train_labels.append(df.loc[df[0] == f][1].values[0])\n",
        "\n",
        "  path = \"/content/1/fragments/train/\"\n",
        "\n",
        "  train_texts = []\n",
        "\n",
        "  for i, f in enumerate(files):\n",
        "    with open(path + f) as f1:\n",
        "        content = f1.read()\n",
        "    train_texts.append(content)\n",
        "\n",
        "  ###################### test\n",
        "  files = os.listdir(\"/content/1/fragments/test\")\n",
        "  path = \"/content/gdrive/MyDrive/NSU Workshop'21 - Readability/Корпусы/fiction_recommended/ratings_test.csv\"\n",
        "  df = pd.read_csv(path, header = None)\n",
        "\n",
        "  test_labels = []\n",
        "  for f in files:\n",
        "    test_labels.append(df.loc[df[0] == f][1].values[0])\n",
        "\n",
        "  path = \"/content/1/fragments/test/\"\n",
        "\n",
        "  test_texts = []\n",
        "\n",
        "  for i, f in enumerate(files):\n",
        "    with open(path + f) as f1:\n",
        "        content = f1.read()\n",
        "    test_texts.append(content)\n",
        "    \n",
        "elif corpus == 'previews':\n",
        "\n",
        "  ###################### train\n",
        "  files = os.listdir(\"/content/gdrive/MyDrive/NSU Workshop'21 - Readability/Корпусы/fiction_previews/train\")\n",
        "\n",
        "  train_labels = []\n",
        "\n",
        "  for f in files:\n",
        "    if f.find('adult')>=0:\n",
        "      train_labels.append(1)\n",
        "    else:\n",
        "      train_labels.append(0)\n",
        "\n",
        "  with open(path_raw_fiction_previews + 'train_fiction_previews.pickle', 'rb') as f:\n",
        "     train_texts = pickle.load(f)\n",
        "  with open(path_raw_fiction_previews + 'train_fiction_previews_labels.pickle', 'rb') as f:\n",
        "      train_labels = pickle.load(f)\n",
        "\n",
        "  ###################### test\n",
        "  files = os.listdir(\"/content/gdrive/MyDrive/NSU Workshop'21 - Readability/Корпусы/fiction_previews/test\")\n",
        "\n",
        "  test_labels = []\n",
        "\n",
        "  for f in files:\n",
        "    if f.find('adult')>=0:\n",
        "      test_labels.append(1)\n",
        "    else:\n",
        "      test_labels.append(0)\n",
        "\n",
        "  with open(path_raw_fiction_previews + 'test_fiction_previews.pickle', 'rb') as f:\n",
        "      test_texts = pickle.load(f)\n",
        "  with open(path_raw_fiction_previews + 'test_fiction_previews_labels.pickle', 'rb') as f:\n",
        "      test_labels = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpuTUOIIRBpf"
      },
      "source": [
        "#RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lqIY9nJQqvU"
      },
      "source": [
        "!pip install tensorboardX\n",
        "!pip install simpletransformers\n",
        "\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "import logging\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDqM_4FTRFP-"
      },
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJiDgsyVBsiB"
      },
      "source": [
        "train_data = pd.DataFrame({'text':train_texts, 'labels':train_labels}).sample(frac=1)\n",
        "test_data = pd.DataFrame({'text':test_texts, 'labels':test_labels})\n",
        "\n",
        "model_args = ClassificationArgs(num_train_epochs=3, overwrite_output_dir=True,\\\n",
        "                                output_dir = '/content/gdrive/MyDrive/output', save_steps = 3000, save_model_every_epoch = True,\\\n",
        "                                #train_batch_size = 1, eval_batch_size = 1,\\\n",
        "                                    no_save = False, max_seq_length=512, n_gpu = 1)\n",
        "model = ClassificationModel('roberta', 'sberbank-ai/ruRoberta-large', args=model_args, num_labels=len(set(train_labels)), use_cuda = True) \n",
        "\n",
        "model.train_model(train_data)\n",
        "result, model_outputs, wrong_predictions = model.eval_model(test_data)\n",
        "\n",
        "true_res = test_data.labels.values\n",
        "print(f1_score(model_outputs.argmax(axis = 1), true_res, average = 'weighted'), \\\n",
        "      precision_score(model_outputs.argmax(axis = 1), true_res, average = 'weighted'), \\\n",
        "      recall_score(model_outputs.argmax(axis = 1), true_res, average = 'weighted'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}